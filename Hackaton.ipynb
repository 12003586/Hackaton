{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfhX1vArV393Vj+hAZnx2R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/12003586/Hackaton/blob/main/Hackaton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mIPDxv7atTMz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import urllib.request\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "from PIL import Image\n",
        "from PIL.ImageEnhance import Color, Contrast, Brightness\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model as tf_Model\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv2D, Dropout, MaxPooling2D\n",
        "from tensorflow.keras import optimizers as tf_optim\n",
        "\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, OneHotEncoder\n",
        "\n",
        "import sklearn.metrics as metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.VGG16(\n",
        "    weights='imagenet',\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False)"
      ],
      "metadata": {
        "id": "ZE8MW42OHk83",
        "outputId": "29c2d004-88b8-4ad9-974b-606a8ddbbbad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "ZWdAEVnqIHTN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create inputs with correct shape\n",
        "inputs = keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "x = base_model(inputs, training=False)\n",
        "\n",
        "# Add pooling layer or flatten layer\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Add final dense layer\n",
        "outputs = keras.layers.Dense(10, activation = 'softmax')(x)\n",
        "\n",
        "# Combine inputs and outputs to create model\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "RYZM-V3KIQvA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "W4blkjFyIl51",
        "outputId": "49281495-842f-4be0-cca2-a94a46eb0625",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 512)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,719,818\n",
            "Trainable params: 5,130\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy' , metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "CJSmjZXuI0VL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    zoom_range=0.1,  # Randomly zoom image\n",
        "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images horizontally\n",
        "    vertical_flip=False, # Don't randomly flip images vertically\n",
        ")"
      ],
      "metadata": {
        "id": "PTYPyA9mI5KC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_it = datagen.flow_from_directory('data/fruits/train/', \n",
        "                                       target_size=(224, 224), \n",
        "                                       color_mode='rgb', \n",
        "                                       class_mode=\"categorical\")\n",
        "# load and iterate validation dataset\n",
        "valid_it = datagen.flow_from_directory('data/fruits/valid', \n",
        "                                      target_size=(224,224), \n",
        "                                      color_mode='rgb', \n",
        "                                      class_mode=\"categorical\")"
      ],
      "metadata": {
        "id": "3UneLEtiKvEz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}